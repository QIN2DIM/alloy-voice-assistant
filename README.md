# Sample AI assistant

You need an `OPENAI_API_KEY` and a `GOOGLE_API_KEY` to run this code. Store them in a `.env` file in the root directory of the project, or set them as environment variables.


If you are running the code on Apple Silicon, run the following command:

```
$ brew install portaudio
```

Create a virtual environment, update pip, and install the required packages:

```
$ python3 -m venv .venv
$ source .venv/bin/activate
$ pip install -U pip
$ pip install -r requirements.txt
```

Run the assistant:

```
$ python3 assistant.py
```

## S2S Request å¤ç° Video <é—®, ç­”>

1. ã€1ã€‘Real-time @asrï¼ˆSenseVoiceï¼‰
2. [1] LLM Chain ï¼ˆGPT-4oï¼‰ å¤„ç†è§†è§‰å’Œæ–‡æœ¬ï¼Œæ ¹æ® prompt å’Œèº«ä»½è®¾å®šï¼Œoutput å£è¯­åŒ–çš„ä¸­æ–‡å†…å®¹
3. [1]CosyVoice @tts zero-shot æœ—è¯»ä¸­æ–‡å†…å®¹

## WSS åŒå·¥é€šä¿¡å¤ç° WebRTC

1. SenseVoice wss serverï¼ŒåŒå‘é˜€è¯­éŸ³å”¤é†’
2. [x] CosyVoice SFT å¿«é€Ÿå”¤é†’



### FunASR å®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡

[Documentation](https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_advanced_guide_online_zh.md)

```bash
cd FunASR/runtime
nohup bash run_server_2pass.sh \
  --download-model-dir /workspace/models \
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \
  --model-dir damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx  \
  --online-model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx  \
  --punc-dir damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx \
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \
  --itn-dir thuduj12/fst_itn_zh \
  --hotword /workspace/models/hotwords.txt > log.txt 2>&1 &
```

```bash
cd FunASR/runtime
nohup bash run_server.sh \
  --download-model-dir /workspace/models \
  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \
  --model-dir iic/SenseVoiceSmall \
  --punc-dir damo/punc_ct-transformer_cn-en-common-vocab471067-large-onnx \
  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \
  --itn-dir thuduj12/fst_itn_zh \
  --hotword /workspace/models/hotwords.txt > log.txt 2>&1 &
```

## TODO

1. ğŸ¶ CABLE Output (VB-Audio Virtual Cable) microphone input device

   ç»“è®ºï¼šç³»ç»Ÿå†…æ’­æ”¾çš„éŸ³é¢‘ï¼Œå°†é€šè¿‡ CABLE ä¼ è¾“åˆ° microphone

2. `xhs ç›´æ’­é—´`ã€`ä¼šè®®è½¯ä»¶`ã€`WebRTC æ³›ç”¨å‹åœºæ™¯` éŸ³é¢‘è¾“å…¥æ¥å£

   ç»“è®ºï¼šç›´æ¥æ’­æ”¾éŸ³é¢‘å³å¯ï¼Œåœ¨éº¦å…‹é£è®¾ç½®é¡¹é€‰æ‹© CABLE

3. LMM è¯­éŸ³äº¤äº’ baseline

   - [ ] éŸ³é¢‘æ–‡ä»¶å†™å…¥æµ‹è¯•ï¼Œä¹Ÿå³ï¼Œâ€œå°†ç¦»çº¿éŸ³é¢‘æ–‡ä»¶é€šè¿‡ microphone å‘é€åˆ° liveâ€
   - [ ] (4~20s) æµå¼å“åº”ï¼Œä¹Ÿå³ï¼Œâ€œæ¨¡å‹è¾“å‡ºèƒ½é€šè¿‡ microphone cable channel å‘é€åˆ° liveâ€
   - [ ] (<1s) å»¶æ—¶ä¼˜åŒ–
   - [ ] (Nice TO Have) åŒå·¥é€šä¿¡

4. LMM é«˜çº§äº¤äº’ best-cases

   1. â€œçœ‹è§â€å¼¹å¹•ï¼Œè¯­éŸ³äº¤äº’
   2. zero-shot 3s voice copy
   3. ç”¨ä»»æ„ç©å®¶éŸ³è‰²å”±æ­Œ
   4. GraphRAG + CV/NLP Toolkit
   5. ï¼ˆA+ï¼‰24h æƒ…æ„Ÿé™ªä¼´
















